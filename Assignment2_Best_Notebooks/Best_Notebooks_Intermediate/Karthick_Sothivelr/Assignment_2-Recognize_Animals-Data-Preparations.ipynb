{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 (Recognize Animals)\n",
    "\n",
    "- #### Objective:\n",
    "    - Train deep learning model that would recognize the name of the animal from its images\n",
    "        - The model should be able to recognize and differentiate between 5 animals\n",
    "        - 5 categories/classes: butterfly, sheep, cow, squirrel, elephant:\n",
    "        - mucca (cow), pecora (sheep), elefante (elephant), farfalla (butterfly) and scoiattolo (squirrel)\n",
    "\n",
    "\n",
    "- In this notebook TASK 1, TASK 2 and some portion of TASK 5 (splitting training images into train and validation set) are perfomed. Details of the tasks perfomed:\n",
    "\n",
    "    - #### Loading the train and test images and converting them into arrays\n",
    "    \n",
    "    - #### Apply preprocessing steps:\n",
    "        - Resize images - Justification: Neural Network will expected inputs of the same size. Therefore, all images need to be resized to a fixed size before inputting them to Neural Network (Chosen size was (128, 128))\n",
    "        - Convert all images to same color mode: Justification: All the images will be in the same desired color mode that we expect from the out of samples images (Chosen color mode was RGB)\n",
    "        - Sacaling (normalize) the image so that pixel values will be between 0 and 1\n",
    "            - Justification:\n",
    "                1) Improve the speed of model training\n",
    "                2) Pixel magnitudes will be uniform for the images\n",
    "    \n",
    "    - #### Display sample images along with its corresponsing labels\n",
    "    \n",
    "    - #### Spliting the training data into train and validation set with ratio of 80:20 (i.e. 80% train and 20% validation)\n",
    "    \n",
    "    - #### Save the arrays representing the images as pickle file - to be used for building the models in the subsequent notebooks/steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, ParameterSampler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from PIL import Image\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import datetime\n",
    "import pathlib\n",
    "import pickle\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Loading Data\n",
    "- Load the data and save it in appropriate variables. Display an image and its corresponding label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Data directory\n",
    "data_dir = os.path.join(os.getcwd(), 'animal_dataset_intermediate', 'train')\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "# Parameters (Desired height and width of images) [Images will be resized to specified height and width]\n",
    "height = 128\n",
    "width = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the type of image file extensions (e.g. jpg, jpeg, png, etc.) that exists in the provided train image dataset\n",
    "# Will be used to filter out non-image file exists in the folder (e.g. to filter out txt file in the provided train image folder)\n",
    "\n",
    "possible_ext = []\n",
    "for class_name in os.listdir(data_dir):\n",
    "    possible_ext.extend([os.path.splitext(filename)[1][1:] for filename in os.listdir(os.path.join(data_dir, class_name))])\n",
    "\n",
    "possible_ext = list(set(possible_ext))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the total number of images present in the train image dataset\n",
    "image_count = 0\n",
    "for ext in list(possible_ext):\n",
    "    if ext=='txt':\n",
    "        continue\n",
    "    image_count = image_count + len(list(data_dir.glob('*/*.{}'.format(ext))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Read Images from the folder and converting into array after resizing and converting them into desired color mode\n",
    "\n",
    "def image_to_array(data_dir, exts, total_images, height=256, width=256, channel=3):\n",
    "    dataset = np.zeros((total_images, height, width, channel))\n",
    "    y_train = np.zeros((total_images, 1), dtype=int)\n",
    "    y_train_labels = np.zeros((total_images, 1), dtype=object)\n",
    "    \n",
    "    class_names = os.listdir(data_dir) #[x.split('_')[0] for x in os.listdir(data_dir)]\n",
    "    j = 0\n",
    "    idx_to_class = dict()\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        idx_to_class[i] = class_name.split('_')[0]\n",
    "        for ext in exts:\n",
    "            for filename in glob.glob(os.path.join(data_dir, class_name, \"*.{}\".format(ext))):\n",
    "                if ext==\"txt\":\n",
    "                    continue\n",
    "                \n",
    "                im = Image.open(filename)\n",
    "                im = im.resize((height, width))\n",
    "                pixels = np.asarray(im).astype('float32')\n",
    "                \n",
    "                if len(pixels.shape)==2:\n",
    "                    pixels = cv2.cvtColor(pixels, cv2.COLOR_GRAY2BGR)\n",
    "                \n",
    "                if pixels.shape[2]!=channel:\n",
    "                    #pixels = cv2.cvtColor(pixels, cv2.COLOR_BGRA2RGB)\n",
    "                    pixels = cv2.cvtColor(pixels, cv2.COLOR_RGBA2RGB)\n",
    "                \n",
    "                pixels /= 255.0\n",
    "                \n",
    "                dataset[j, :, :, :] = pixels\n",
    "                y_train[j, :] = i\n",
    "                y_train_labels[j, :] = class_name.split('_')[0]\n",
    "                \n",
    "                j += 1\n",
    "    \n",
    "    return dataset, y_train, y_train_labels, idx_to_class\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Images from training image folder using the 'image_to_array' function defined earlier\n",
    "X_train, y_train, y_train_labels, idx_to_class = image_to_array(data_dir=data_dir, exts=possible_ext, \n",
    "                                                                total_images=image_count, height=height, \n",
    "                                                                width=width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of training dataset: 8196\n",
      "Shape of Train: (8196, 128, 128, 3)\n",
      "Number of classes: 5\n",
      "\n",
      "\n",
      "Number of train samples by class: \n",
      "Class Labels: ['elefante' 'farfalla' 'mucca' 'pecora' 'scoiattolo']\n",
      "Number of Samples: [1301 1901 1680 1638 1676]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Understanding the Data \n",
    "# Get an idea on the number of samples for each class (Whether we are dealing with extremely imbalanced classes)\n",
    "# Print out the findings\n",
    "print(f\"Total number of training dataset: {len(X_train)}\")\n",
    "print(f\"Shape of Train: {X_train.shape}\")\n",
    "\n",
    "unique_elements, counts_elements = np.unique(y_train_labels, return_counts=True)\n",
    "\n",
    "print(f\"Number of classes: {len(unique_elements)}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f'''Number of train samples by class: \n",
    "Class Labels: {unique_elements}\n",
    "Number of Samples: {counts_elements}''')\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments:\n",
    "- There are 8196 images in the train folder.\n",
    "- Number of samples for 'elefante' class appear to less than other class and samples for 'farfalla' appear to be more than other samples.\n",
    "- If in later stages, the model performance was poor in terms of recall and F-1 score (model favors majority classes) - should consider using techniques to handle imbalance in the dataset like oversampling, undersampling, combination of oversampling and undersampling, weighted random sampler, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Sample Image from Each Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = unique_elements\n",
    "\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "for i in range(len(class_names)):\n",
    "    ax = fig.add_subplot(3, 2, 1 + i, xticks=[], yticks=[])\n",
    "    idx = np.where(y_train[:]==i)[0]\n",
    "    features_idx = X_train[idx,::]\n",
    "    img_num = np.random.randint(features_idx.shape[0])\n",
    "    im = np.transpose(features_idx[img_num,::], (0, 1, 2))\n",
    "    ax.set_title(class_names[i])\n",
    "    plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View A Single Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample_image(X_train, y_train, image_id):\n",
    "    print(f\"Class Label: {y_train[image_id]}\")\n",
    "    print(f\"Label Name: {y_train_labels[image_id]}\")\n",
    "    plt.imshow(X_train[image_id]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Some Sample Images\n",
    "show_sample_image(X_train, y_train, image_id=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test Data\n",
    "- Loading and preparing test data, so that will be easier to generate output for submission later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Test List\n",
    "test_list = pd.read_csv(os.path.join(os.path.dirname(data_dir), \"Testing_set_animals.csv\"))\n",
    "test_filename = list(test_list[\"filename\"].values)\n",
    "total_images = len(test_filename)\n",
    "\n",
    "# Define Test Dir\n",
    "test_dir = os.path.join(os.path.dirname(data_dir), 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read and convert test images to array (Slightly modified version of the previous image_to_array function)\n",
    "\n",
    "def test_image_to_array(test_dir, test_filename, total_images, height=256, width=256, channel=3):\n",
    "    dataset = np.zeros((total_images, height, width, channel))\n",
    "    \n",
    "    for i, file_name in enumerate(test_filename):\n",
    "        img_dir = os.path.join(test_dir, file_name)\n",
    "        \n",
    "        im = Image.open(img_dir)\n",
    "        im = im.resize((height, width))\n",
    "        pixels = np.asarray(im).astype('float32')\n",
    "        \n",
    "        if len(pixels.shape)==2:\n",
    "            pixels = cv2.cvtColor(pixels, cv2.COLOR_GRAY2RGB)\n",
    "        \n",
    "        if pixels.shape[2]!=channel:\n",
    "            pixels = cv2.cvtColor(pixels, cv2.COLOR_RGBA2RGB)\n",
    "        \n",
    "        pixels /= 255.0\n",
    "        \n",
    "        dataset[i, :, :, :] = pixels\n",
    "    \n",
    "    return dataset\n",
    "# Gray scale image at 579"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_image_to_array(test_dir=test_dir, test_filename=test_filename, \n",
    "                             total_images=total_images, height=height, width=width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Pre-processing\n",
    "- Apply the required pre-processing steps on the image data. These may include scaling, converting to grayscale or anything else. Justify your decision about performing those particular pre-processing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the X data\n",
    "max_val = X_train.max()\n",
    "X_train = X_train/max_val\n",
    "X_test = X_test/max_val\n",
    "\n",
    "# One-hot encode the output\n",
    "y_train_cat = to_categorical(y_train)\n",
    "\n",
    "\n",
    "width = X_train.shape[1]\n",
    "height = X_train.shape[2]\n",
    "channel = X_train.shape[3]\n",
    "\n",
    "num_samples = X_train.shape[0]\n",
    "n_features = width*height*channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Subset of Task 5\n",
    "- Divide the train data into train and validation set in a ratio of 80:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr_cat, y_val_cat = train_test_split(X_train, y_train_cat, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Save Preprocessed Train, Val and Test for Further Processing\\n# Train\\nwith open('X_train.pkl', 'wb') as f: pickle.dump(X_tr, f, protocol=pickle.HIGHEST_PROTOCOL)\\nwith open('y_train.pkl', 'wb') as f: pickle.dump(y_tr_cat, f, protocol=pickle.HIGHEST_PROTOCOL)\\n\\n# Validation\\nwith open('X_val.pkl', 'wb') as f: pickle.dump(X_val, f, protocol=pickle.HIGHEST_PROTOCOL)\\nwith open('y_val.pkl', 'wb') as f: pickle.dump(y_val_cat, f, protocol=pickle.HIGHEST_PROTOCOL)\\n\\n# Test\\nwith open('X_test.pkl', 'wb') as f: pickle.dump(X_test, f, protocol=pickle.HIGHEST_PROTOCOL)\\n\\n# Class Info\\nwith open('idx_to_class.pkl', 'wb') as f: pickle.dump(idx_to_class, f, protocol=pickle.HIGHEST_PROTOCOL)\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Save Preprocessed Train, Val and Test for Further Processing\n",
    "# Train\n",
    "with open('X_train.pkl', 'wb') as f: pickle.dump(X_tr, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('y_train.pkl', 'wb') as f: pickle.dump(y_tr_cat, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Validation\n",
    "with open('X_val.pkl', 'wb') as f: pickle.dump(X_val, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('y_val.pkl', 'wb') as f: pickle.dump(y_val_cat, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Test\n",
    "with open('X_test.pkl', 'wb') as f: pickle.dump(X_test, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Class Info\n",
    "with open('idx_to_class.pkl', 'wb') as f: pickle.dump(idx_to_class, f, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
