{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xyghK7biffyE"
   },
   "outputs": [],
   "source": [
    "# Loading required Libraries\n",
    "from __future__ import print_function, division\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import plotly.express as px\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import itertools\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import models, transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(0)\n",
    "\n",
    "# External Packages\n",
    "!pip -q install --upgrade pip\n",
    "!pip -q install torchsummary torch-lr-finder\n",
    "from torchsummary import summary as model_arch\n",
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "# TensorBoard Loadout\n",
    "from tensorflow import summary\n",
    "import datetime\n",
    "%reload_ext tensorboard\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ovbrvEgsuYMG"
   },
   "source": [
    "# TASK 1: Loading Data \n",
    "* We used `google_drive_downloader` for load dataset to colab environment.\n",
    "* Using `glob` & `Pillow`, we loaded all the images for modelling pipeline.\n",
    "> Few images had an extra `alpha` channel, so for consitency we explicity converted images to **RBG** format.\n",
    "* Using the collection of images, we created **Custom PyTorch Dataset** followed by **Data Loaders**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QPBFCj52fKPl",
    "outputId": "bb6bec94-4e66-4752-b223-e28f2881f690"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already present\n"
     ]
    }
   ],
   "source": [
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "\n",
    "if os.path.exists('./data/animal_dataset_intermediate/')==False:\n",
    "  gdd.download_file_from_google_drive(file_id='176E-pLhoxTgWsJ3MeoJQV_GXczIA6g8D',\n",
    "                                      dest_path='./data/animal_dataset_intermediate.zip',\n",
    "                                      unzip=True, showsize=True, overwrite = False)\n",
    "  print('Removed Zip post working'.upper())\n",
    "  os.path.exists('./data/animal_dataset_intermediate.zip')\n",
    "else:\n",
    "  print(\"Data already present\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "an7OFu2aj3GY",
    "outputId": "7ab60a61-6016-4fb1-ed2a-1c67a9c814a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning Folder Names\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = './data/animal_dataset_intermediate/train/'\n",
    "print('Cleaning Folder Names')\n",
    "for i in os.listdir(DATA_PATH):\n",
    "  os.renames(DATA_PATH+i,DATA_PATH+i.split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ObzLsqvMgCvS"
   },
   "outputs": [],
   "source": [
    "def GetImagesFromFolder(PATH,Class_Folder,ext):\n",
    "    images = [Image.open(file).convert('RGB') for e in ext for file in glob.glob(PATH+Class_Folder+'/*.' + e)]\n",
    "    print(f\"Found {len(images)} in folder {Class_Folder}\")\n",
    "    np.random.shuffle(images)\n",
    "    return images,np.array([Class_Folder for i in range(len(images))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I3ntTItvgInE"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = './data/animal_dataset_intermediate/train/'\n",
    "FOLDERS = os.listdir(DATA_PATH)\n",
    "ext = ['jpg','jpeg','png']\n",
    "le = LabelEncoder().fit(FOLDERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "wWNQ6pKFgfYR",
    "outputId": "c5122721-56c7-416a-fd9e-2dd7a16227bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1676 in folder scoiattolo\n",
      "Found 1680 in folder mucca\n",
      "Found 1901 in folder farfalla\n",
      "Found 1638 in folder pecora\n",
      "Found 1301 in folder elefante\n"
     ]
    }
   ],
   "source": [
    "ALL_IMAGES,ALL_LABELS = [],[]\n",
    "images_population ={}\n",
    "\n",
    "for Class_Folder in FOLDERS:\n",
    "    IMAGES,LABELS = GetImagesFromFolder(DATA_PATH,Class_Folder,ext)\n",
    "    images_population[Class_Folder] = LABELS.shape[0]\n",
    "    ALL_IMAGES.extend(IMAGES)\n",
    "    ALL_LABELS.extend(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "colab_type": "code",
    "id": "TUYJBvmnhm3w",
    "outputId": "732851de-6676-46b8-931c-292b4299fd5e"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict({'Name':[i.capitalize() for i in images_population.keys()],'#Images':[i for i in images_population.values()]})\n",
    "\n",
    "colors = ['gold', 'mediumturquoise', 'darkorange', 'lightgreen','olive']\n",
    "fig = px.pie(df,values='#Images',names='Name', hole=.3, width=600, height=600)\n",
    "fig.update_traces(hoverinfo='label+percent',textfont_size=20, marker=dict(colors=colors, line=dict(color='#000000', width=2)))\n",
    "fig.update_layout( title={'text': 'Population of Various Classes','y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sSNBK2MXhnUz"
   },
   "outputs": [],
   "source": [
    "# For benchmarking we have make 3 stratified splits(Train-Test-Validation) of 80:10:10 respectively.\n",
    "from sklearn.model_selection import train_test_split\n",
    "TRAIN_IMAGES, X_val_test, TRAIN_LABELS, y_val_test = train_test_split(ALL_IMAGES, ALL_LABELS, test_size=0.20, random_state=42,stratify=ALL_LABELS)\n",
    "VAL_IMAGES, TEST_IMAGES, VAL_LABELS, TEST_LABELS =  train_test_split(X_val_test, y_val_test, test_size=0.50, random_state=42,stratify=y_val_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A_yL_TEvlfGF"
   },
   "outputs": [],
   "source": [
    "# Creating Custom PyTorch Dataset\n",
    "class Animal_Dataset(Dataset):\n",
    "    def __init__(self, ImageData, Target, transform=None):\n",
    "        self.ImageData = ImageData\n",
    "        self.Target = torch.LongTensor(le.transform(Target))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.ImageData[index]\n",
    "        y = self.Target[index]\n",
    "        if self.transform:\n",
    "            x = Image.fromarray(np.uint8(np.array(self.ImageData[index])))\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "    def __len__(self):\n",
    "        return len(self.ImageData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5mE64w4LumB1"
   },
   "source": [
    "# TASK 2: Pre-processing\n",
    "\n",
    "| Augmentation        \t| Definition                                                              \t|            Use           \t|\n",
    "|----------------------\t|-------------------------------------------------------------------------\t|:------------------------:\t|\n",
    "| ColorJitter          \t| Randomly change the brightness, contrast and   saturation of an image.  \t|      Color Variance      \t|\n",
    "| RandomRotation       \t| Rotate the image by angle                                               \t|    Positional Variance   \t|\n",
    "| Resize               \t| Resize the input PIL Image to the given size.                           \t|    Positional Variance   \t|\n",
    "| RandomResizedCrop    \t| Crop the given PIL Image to random size and   aspect ratio.             \t|     Data Compression     \t|\n",
    "| RandomVerticalFlip   \t| Vertically flip the given PIL Image randomly                            \t|    Positional Variance   \t|\n",
    "| RandomHorizontalFlip \t| Horizontally flip the given PIL Image   randomly                        \t|    Positional Variance   \t|\n",
    "| ToTensor             \t| Convert a PIL Image or numpy.ndarray to tensor                        \t| PyTorch Internal Working \t|\n",
    "| RandomErasing        \t| Randomly selects a rectangle region in an   image and erases its pixels \t|  Generalize the learning \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "mhl9JLeymQ83",
    "outputId": "7c5e1013-f6d5-4588-d8f3-fe7311027fac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size for Dataset:\n",
      "\t* Train: 6556\n",
      "\t* Valid: 820\n",
      "\t* Test: 820\n"
     ]
    }
   ],
   "source": [
    "#  Augmentation used for enriching dataset\n",
    "transform = {'train':transforms.Compose([transforms.ColorJitter(),\n",
    "                                         transforms.RandomRotation(30),\n",
    "                                         transforms.Resize((230,230)),\n",
    "                                         transforms.RandomResizedCrop(225),\n",
    "                                        #  transforms.RandomVerticalFlip(),\n",
    "                                         transforms.RandomHorizontalFlip(),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.RandomErasing()\n",
    "                                         ]),\n",
    "             \n",
    "             'val':transforms.Compose([transforms.Resize((225,225)),\n",
    "                                      transforms.ToTensor()]),\n",
    "             \n",
    "             'test':transforms.Compose([transforms.Resize((225,225)),\n",
    "                                      transforms.ToTensor()])}\n",
    "# Used to see if GPU is available or not?\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Defining Batch sizes for all the 3 splits\n",
    "# Batch Size for Validation & Test data is higher to speed up prediction\n",
    "batch_size = {'train':256, 'val':512,'test':512}\n",
    "\n",
    "dataset_classes = ['farfalla', 'elefante', 'mucca', 'pecora', 'scoiattolo']\n",
    "\n",
    "# Using custom dataset class to load Image Data as tensors.\n",
    "image_datasets = {'train': Animal_Dataset(TRAIN_IMAGES, TRAIN_LABELS, transform=transform['train']),\n",
    "                  'val':   Animal_Dataset(VAL_IMAGES, VAL_LABELS, transform=transform['val']),\n",
    "                  'test':  Animal_Dataset(TEST_IMAGES, TEST_LABELS, transform=transform['test'])}\n",
    "\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val','test']}\n",
    "\n",
    "# Creating Iterators for Dataset\n",
    "dataloaders = {indx: DataLoader(image_datasets[indx], batch_size=batch_size[indx], num_workers=2, pin_memory=False, shuffle=True)\n",
    "              for indx in batch_size.keys()}\n",
    "\n",
    "print(\"Size for Dataset:\\n\\t* Train: %d\\n\\t* Valid: %d\\n\\t* Test: %d\"%(dataset_sizes['train'],dataset_sizes['val'],dataset_sizes['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6uWxFMpmmXa5"
   },
   "outputs": [],
   "source": [
    "# Helper function to display the image\n",
    "def imshow(img):\n",
    "    # Convert from tensor image\n",
    "    plt.imshow(np.transpose(img, (1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "id": "pUFBvE-VmpbP",
    "outputId": "3b815b14-91b7-464c-9a75-089f03cd7606"
   },
   "outputs": [],
   "source": [
    "# Get one batch of training images\n",
    "dataiter = iter(dataloaders['train'])\n",
    "images, labels = dataiter.next()\n",
    "# Convert images to numpy for display\n",
    "images = images.numpy()\n",
    "\n",
    "# Plot the images in the batch\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "\n",
    "labels = le.inverse_transform([i.item() for i in labels])\n",
    "\n",
    "# Display 20 images\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    imshow(images[idx])\n",
    "    ax.set_title(labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "id": "2Bzi7rztm2Xa",
    "outputId": "7d240472-4388-4874-9e0d-64ad73cb39bf"
   },
   "outputs": [],
   "source": [
    "# Get one batch of validation images\n",
    "dataiter = iter(dataloaders['val'])\n",
    "images, labels = dataiter.next()\n",
    "# Convert images to numpy for display\n",
    "images = images.numpy()\n",
    "\n",
    "# Plot the images in the batch\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "\n",
    "# Display 20 images\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    imshow(images[idx])\n",
    "    ax.set_title(dataset_classes[labels[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GAkibLhzofJ2"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, model_checkpoint=0, early_stop = 10, num_epochs=5):\n",
    "  model = model.to(device)\n",
    "\n",
    "  # number of epochs to train the model\n",
    "  valid_loss_min = np.Inf # track change in validation loss\n",
    "  early_stop_cnt = 0\n",
    "  last_epoch_loss = np.Inf\n",
    "  globaliter = 0\n",
    "\n",
    "  final_loss = np.Inf\n",
    "\n",
    "  for epoch in range(1, num_epochs+1):\n",
    "\n",
    "      globaliter+=1\n",
    "      # keep track of training and validation loss\n",
    "      train_loss = 0.0\n",
    "      valid_loss = 0.0\n",
    "\n",
    "      \n",
    "      ###################\n",
    "      # train the model #\n",
    "      ###################\n",
    "      model.train()\n",
    "      train_corrects = 0\n",
    "\n",
    "      for data, target in dataloaders['train']:\n",
    "          data, target = data.to(device), target.to(device)\n",
    "          # clear the gradients of all optimized variables\n",
    "          optimizer.zero_grad()\n",
    "          # forward pass: compute predicted outputs by passing inputs to the model\n",
    "          output = model(data)\n",
    "          _, preds = torch.max(output, 1)\n",
    "          # calculate the batch loss\n",
    "          loss = criterion(output, target)\n",
    "          # backward pass: compute gradient of the loss with respect to model parameters\n",
    "          loss.backward()\n",
    "          # perform a single optimization step (parameter update)\n",
    "          optimizer.step()\n",
    "          # update training loss\n",
    "          train_loss += loss.item()*data.size(0)\n",
    "          train_corrects += torch.sum(preds == target.data)\n",
    "      \n",
    "      train_loss = train_loss/len(dataloaders['train'].dataset)\n",
    "      train_acc = (train_corrects.double()*100)/len(dataloaders['train'].dataset)\n",
    "      with train_summary_writer.as_default():\n",
    "          summary.scalar('loss', train_loss, step=epoch)\n",
    "          summary.scalar('accuracy', train_acc.item(), step=epoch)\n",
    "          \n",
    "      ######################    \n",
    "      # validate the model #\n",
    "      ######################\n",
    "      model.eval()\n",
    "      val_corrects = 0\n",
    "      for data, target in dataloaders['val']:\n",
    "          data, target = data.to(device), target.to(device)\n",
    "          # forward pass: compute predicted outputs by passing inputs to the model\n",
    "          output = model(data)\n",
    "          _, preds = torch.max(output, 1)\n",
    "          # calculate the batch loss\n",
    "          loss = criterion(output, target)\n",
    "          # update average validation loss\n",
    "          valid_loss += loss.item()*data.size(0)\n",
    "          val_corrects += torch.sum(preds == target.data)\n",
    "      \n",
    "      # calculate average losses\n",
    "      valid_loss = valid_loss/len(dataloaders['val'].dataset)\n",
    "      valid_acc = (val_corrects.double()*100)/len(dataloaders['val'].dataset)\n",
    "      with test_summary_writer.as_default():\n",
    "          summary.scalar('loss', valid_loss, step=epoch)\n",
    "          summary.scalar('accuracy', valid_acc.item(), step=epoch)\n",
    "          \n",
    "      # print training/validation statistics \n",
    "      print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch, train_loss, valid_loss))\n",
    "      print('\\t\\tTraining Acc:  {:.3f} \\t\\tValidation Acc:{:.3f}'.format(train_acc, valid_acc))\n",
    "      \n",
    "      # save model if validation loss has decreased\n",
    "      if valid_loss <= valid_loss_min:\n",
    "          print('\\t\\tValidation loss decreased ({:.6f} --> {:.6f}).'.format(valid_loss_min,valid_loss))\n",
    "          if model_checkpoint != 0:\n",
    "            torch.save(model.state_dict(), 'model.pt'.format(train_acc, valid_acc))\n",
    "            print('Model Saved: model.pt'.format(train_acc, valid_acc))\n",
    "          valid_loss_min = valid_loss\n",
    "      elif valid_loss == np.nan:\n",
    "        print(\"Model Loss: NAN\")\n",
    "\n",
    "      if (last_epoch_loss < valid_loss) and last_epoch_loss != np.Inf:\n",
    "        early_stop_cnt +=1\n",
    "        if early_stop_cnt == early_stop:\n",
    "          print('-'*50+\"\\nEarly Stopping Hit\\n\"+'-'*50)\n",
    "          break\n",
    "        else:\n",
    "          print('-'*50+f\"\\n\\t\\tEarly Stopping Step: {early_stop_cnt}/{early_stop}\\n\"+'-'*50)\n",
    "      else:\n",
    "        early_stop_cnt = 0\n",
    "        last_epoch_loss = valid_loss\n",
    "\n",
    "  print(f\"Training Completed with best model having loss of {valid_loss_min}\")\n",
    "  del data,target\n",
    "  gc.collect()\n",
    "  return model\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    size = len(classes)*2\n",
    "    plt.figure(figsize = (size,size))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title,fontsize=20)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes,fontsize=12)\n",
    "    plt.yticks(tick_marks, classes,fontsize=12)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label',fontsize=16)\n",
    "    plt.xlabel('Predicted label',fontsize=16)\n",
    "\n",
    "    \n",
    "def model_verification(loader,batch_size,model,n_classes=5):\n",
    "    classes = list(le.inverse_transform([i for i in range(n_classes)]))\n",
    "    prediction_list,label_list = [],[]\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "          images = images.to(device)\n",
    "          labels = labels.to(device)\n",
    "          outputs = model(images)\n",
    "          predicted = outputs.argmax(dim=1).detach()\n",
    "          prediction_list.extend(predicted.tolist())\n",
    "          label_list.extend(labels.tolist())\n",
    "    cm = confusion_matrix(prediction_list,label_list)\n",
    "    plot_confusion_matrix(cm, classes)\n",
    "    if device.type == 'cuda':\n",
    "      images = images.cpu()\n",
    "      labels = labels.cpu()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure(figsize = (num_images,num_images))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['test']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'Predicted: {dataset_classes[preds[j]]} | Actual: {dataset_classes[labels[j]]}')\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)\n",
    "    if device.type == 'cuda':\n",
    "      inputs = inputs.cpu()\n",
    "      labels = labels.cpu()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uMyH54nBsJ6p"
   },
   "source": [
    "# TASK 3: Building a Multi-Layer Perceptron\n",
    "> In our model, we have 5 Dense layers each with a dropout layer for regularization.\n",
    "* We have used ReLu activation function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "HuZUzXDNqc7z",
    "outputId": "49b7703e-da94-47c4-c69c-5cafa6908c13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Animal_NN(\n",
       "  (fc1): Linear(in_features=151875, out_features=1536, bias=True)\n",
       "  (fc2): Linear(in_features=1536, out_features=768, bias=True)\n",
       "  (fc3): Linear(in_features=768, out_features=384, bias=True)\n",
       "  (fc4): Linear(in_features=384, out_features=128, bias=True)\n",
       "  (fc5): Linear(in_features=128, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 3*225*225\n",
    "output_size = 5\n",
    "\n",
    "\n",
    "class Animal_NN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.fc1 = nn.Linear(input_size, 1536)\n",
    "    self.fc2 = nn.Linear(1536, 768)\n",
    "    self.fc3 = nn.Linear(768, 384)\n",
    "    self.fc4 = nn.Linear(384, 128)\n",
    "    self.fc5 = nn.Linear(128, output_size)\n",
    "\n",
    "  def forward(self, xb):\n",
    "    # Flatten images into vectors\n",
    "    out = xb.view(xb.size(0), -1)\n",
    "    # Apply layers & activation functions\n",
    "    out = self.fc1(out)\n",
    "    out = F.relu(F.dropout(out))\n",
    "    out = self.fc2(out)\n",
    "    out = F.relu(F.dropout(out))\n",
    "    out = self.fc3(out)\n",
    "    out = F.relu(F.dropout(out))\n",
    "    out = self.fc4(out)\n",
    "    out = F.relu(F.dropout(out))\n",
    "    out = self.fc5(out)\n",
    "    return out\n",
    "\n",
    "model_nn = Animal_NN().to(device)\n",
    "model_nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BCDpZA1MvClf"
   },
   "source": [
    "# TASK 4: Optimizer\n",
    "> * For Optimizer, we are using `SGD` with learning rate 0.01\n",
    "* For Loss Function, we are using `CrossEntropyLoss` due to multi-class classification.\n",
    "* Metric for our case is accuracy, our loss function will penalize for wrong prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "22pGGRXgq_z6"
   },
   "outputs": [],
   "source": [
    "# Cross Entropy Loss \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "decay = 0.0001\n",
    "optimizer_ft = optim.SGD(model_nn.parameters(), lr=lr, momentum = momentum, weight_decay = decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PLkClqrzvTGV"
   },
   "source": [
    "# TASK 5: Training the model\n",
    "> * Fit the model to the data by dividing the train data into train and validation set in a ratio of 80:20. \n",
    "* Decide the number of epochs and ensure overfitting doesn’t occur.\n",
    "* For Regularization, we are using \n",
    "\n",
    ">> *   Early Stop: Help loss from deviating\n",
    ">> *   Drop-Out layer: Generalizes model learning thoughout, and not selectively relying on certain neuron output \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3jGubSa2IDBf"
   },
   "outputs": [],
   "source": [
    "current_time = str(datetime.datetime.now().timestamp())\n",
    "train_log_dir = 'logs/tensorboard/ann/train/' + current_time\n",
    "test_log_dir = 'logs/tensorboard/ann/test/' + current_time\n",
    "train_summary_writer = summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = summary.create_file_writer(test_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RenSRhRcvR4i",
    "outputId": "ef5598e7-7de5-4439-db67-19d771583d65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training of Model:\n",
      "Epoch: 1 \tTraining Loss: 1.611771 \tValidation Loss: 1.620606\n",
      "\t\tTraining Acc:  21.599 \t\tValidation Acc:21.463\n",
      "\t\tValidation loss decreased (inf --> 1.620606).\n",
      "Model Saved: model.pt\n",
      "Epoch: 2 \tTraining Loss: 1.611608 \tValidation Loss: 1.608642\n",
      "\t\tTraining Acc:  21.126 \t\tValidation Acc:21.951\n",
      "\t\tValidation loss decreased (1.620606 --> 1.608642).\n",
      "Model Saved: model.pt\n",
      "Epoch: 3 \tTraining Loss: 1.606341 \tValidation Loss: 1.607712\n",
      "\t\tTraining Acc:  22.788 \t\tValidation Acc:22.805\n",
      "\t\tValidation loss decreased (1.608642 --> 1.607712).\n",
      "Model Saved: model.pt\n",
      "Epoch: 4 \tTraining Loss: 1.604441 \tValidation Loss: 1.605759\n",
      "\t\tTraining Acc:  22.819 \t\tValidation Acc:22.317\n",
      "\t\tValidation loss decreased (1.607712 --> 1.605759).\n",
      "Model Saved: model.pt\n",
      "Epoch: 5 \tTraining Loss: 1.602398 \tValidation Loss: 1.606092\n",
      "\t\tTraining Acc:  23.261 \t\tValidation Acc:20.732\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 1/10\n",
      "--------------------------------------------------\n",
      "Epoch: 6 \tTraining Loss: 1.604084 \tValidation Loss: 1.603043\n",
      "\t\tTraining Acc:  23.322 \t\tValidation Acc:22.927\n",
      "\t\tValidation loss decreased (1.605759 --> 1.603043).\n",
      "Model Saved: model.pt\n",
      "Epoch: 7 \tTraining Loss: 1.599787 \tValidation Loss: 1.604207\n",
      "\t\tTraining Acc:  22.987 \t\tValidation Acc:24.512\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 1/10\n",
      "--------------------------------------------------\n",
      "Epoch: 8 \tTraining Loss: 1.598414 \tValidation Loss: 1.593885\n",
      "\t\tTraining Acc:  23.459 \t\tValidation Acc:26.098\n",
      "\t\tValidation loss decreased (1.603043 --> 1.593885).\n",
      "Model Saved: model.pt\n",
      "Epoch: 9 \tTraining Loss: 1.597262 \tValidation Loss: 1.594636\n",
      "\t\tTraining Acc:  23.780 \t\tValidation Acc:24.024\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 1/10\n",
      "--------------------------------------------------\n",
      "Epoch: 10 \tTraining Loss: 1.595957 \tValidation Loss: 1.585570\n",
      "\t\tTraining Acc:  24.283 \t\tValidation Acc:27.805\n",
      "\t\tValidation loss decreased (1.593885 --> 1.585570).\n",
      "Model Saved: model.pt\n",
      "Epoch: 11 \tTraining Loss: 1.592836 \tValidation Loss: 1.582089\n",
      "\t\tTraining Acc:  23.902 \t\tValidation Acc:27.439\n",
      "\t\tValidation loss decreased (1.585570 --> 1.582089).\n",
      "Model Saved: model.pt\n",
      "Epoch: 12 \tTraining Loss: 1.592590 \tValidation Loss: 1.579011\n",
      "\t\tTraining Acc:  25.442 \t\tValidation Acc:26.951\n",
      "\t\tValidation loss decreased (1.582089 --> 1.579011).\n",
      "Model Saved: model.pt\n",
      "Epoch: 13 \tTraining Loss: 1.582587 \tValidation Loss: 1.562382\n",
      "\t\tTraining Acc:  25.839 \t\tValidation Acc:31.585\n",
      "\t\tValidation loss decreased (1.579011 --> 1.562382).\n",
      "Model Saved: model.pt\n",
      "Epoch: 14 \tTraining Loss: 1.580841 \tValidation Loss: 1.548402\n",
      "\t\tTraining Acc:  26.129 \t\tValidation Acc:27.805\n",
      "\t\tValidation loss decreased (1.562382 --> 1.548402).\n",
      "Model Saved: model.pt\n",
      "Epoch: 15 \tTraining Loss: 1.570563 \tValidation Loss: 1.528468\n",
      "\t\tTraining Acc:  26.449 \t\tValidation Acc:32.317\n",
      "\t\tValidation loss decreased (1.548402 --> 1.528468).\n",
      "Model Saved: model.pt\n",
      "Epoch: 16 \tTraining Loss: 1.562367 \tValidation Loss: 1.525606\n",
      "\t\tTraining Acc:  27.913 \t\tValidation Acc:32.439\n",
      "\t\tValidation loss decreased (1.528468 --> 1.525606).\n",
      "Model Saved: model.pt\n",
      "Epoch: 17 \tTraining Loss: 1.559894 \tValidation Loss: 1.519701\n",
      "\t\tTraining Acc:  27.974 \t\tValidation Acc:30.610\n",
      "\t\tValidation loss decreased (1.525606 --> 1.519701).\n",
      "Model Saved: model.pt\n",
      "Epoch: 18 \tTraining Loss: 1.552704 \tValidation Loss: 1.503910\n",
      "\t\tTraining Acc:  28.966 \t\tValidation Acc:32.317\n",
      "\t\tValidation loss decreased (1.519701 --> 1.503910).\n",
      "Model Saved: model.pt\n",
      "Epoch: 19 \tTraining Loss: 1.544911 \tValidation Loss: 1.506244\n",
      "\t\tTraining Acc:  29.042 \t\tValidation Acc:34.024\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 1/10\n",
      "--------------------------------------------------\n",
      "Epoch: 20 \tTraining Loss: 1.547302 \tValidation Loss: 1.496354\n",
      "\t\tTraining Acc:  28.874 \t\tValidation Acc:34.634\n",
      "\t\tValidation loss decreased (1.503910 --> 1.496354).\n",
      "Model Saved: model.pt\n",
      "Epoch: 21 \tTraining Loss: 1.540203 \tValidation Loss: 1.474990\n",
      "\t\tTraining Acc:  30.491 \t\tValidation Acc:36.098\n",
      "\t\tValidation loss decreased (1.496354 --> 1.474990).\n",
      "Model Saved: model.pt\n",
      "Epoch: 22 \tTraining Loss: 1.531910 \tValidation Loss: 1.498497\n",
      "\t\tTraining Acc:  29.912 \t\tValidation Acc:33.537\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 1/10\n",
      "--------------------------------------------------\n",
      "Epoch: 23 \tTraining Loss: 1.529277 \tValidation Loss: 1.468547\n",
      "\t\tTraining Acc:  30.095 \t\tValidation Acc:34.390\n",
      "\t\tValidation loss decreased (1.474990 --> 1.468547).\n",
      "Model Saved: model.pt\n",
      "Epoch: 24 \tTraining Loss: 1.524910 \tValidation Loss: 1.484456\n",
      "\t\tTraining Acc:  31.742 \t\tValidation Acc:36.341\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 1/10\n",
      "--------------------------------------------------\n",
      "Epoch: 25 \tTraining Loss: 1.512503 \tValidation Loss: 1.467702\n",
      "\t\tTraining Acc:  31.788 \t\tValidation Acc:36.951\n",
      "\t\tValidation loss decreased (1.468547 --> 1.467702).\n",
      "Model Saved: model.pt\n",
      "Epoch: 26 \tTraining Loss: 1.507422 \tValidation Loss: 1.468008\n",
      "\t\tTraining Acc:  33.511 \t\tValidation Acc:36.707\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 1/10\n",
      "--------------------------------------------------\n",
      "Epoch: 27 \tTraining Loss: 1.510272 \tValidation Loss: 1.438044\n",
      "\t\tTraining Acc:  32.520 \t\tValidation Acc:37.317\n",
      "\t\tValidation loss decreased (1.467702 --> 1.438044).\n",
      "Model Saved: model.pt\n",
      "Epoch: 28 \tTraining Loss: 1.508655 \tValidation Loss: 1.458825\n",
      "\t\tTraining Acc:  32.688 \t\tValidation Acc:36.341\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 1/10\n",
      "--------------------------------------------------\n",
      "Epoch: 29 \tTraining Loss: 1.511293 \tValidation Loss: 1.471552\n",
      "\t\tTraining Acc:  31.330 \t\tValidation Acc:34.878\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 2/10\n",
      "--------------------------------------------------\n",
      "Epoch: 30 \tTraining Loss: 1.510419 \tValidation Loss: 1.490967\n",
      "\t\tTraining Acc:  31.955 \t\tValidation Acc:36.098\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 3/10\n",
      "--------------------------------------------------\n",
      "Epoch: 31 \tTraining Loss: 1.514175 \tValidation Loss: 1.518156\n",
      "\t\tTraining Acc:  32.215 \t\tValidation Acc:35.244\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 4/10\n",
      "--------------------------------------------------\n",
      "Epoch: 32 \tTraining Loss: 1.512104 \tValidation Loss: 1.467099\n",
      "\t\tTraining Acc:  31.803 \t\tValidation Acc:37.927\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 5/10\n",
      "--------------------------------------------------\n",
      "Epoch: 33 \tTraining Loss: 1.513740 \tValidation Loss: 1.490731\n",
      "\t\tTraining Acc:  31.422 \t\tValidation Acc:36.341\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 6/10\n",
      "--------------------------------------------------\n",
      "Epoch: 34 \tTraining Loss: 1.520850 \tValidation Loss: 1.494826\n",
      "\t\tTraining Acc:  31.254 \t\tValidation Acc:35.244\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 7/10\n",
      "--------------------------------------------------\n",
      "Epoch: 35 \tTraining Loss: 1.511215 \tValidation Loss: 1.475737\n",
      "\t\tTraining Acc:  31.208 \t\tValidation Acc:34.146\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 8/10\n",
      "--------------------------------------------------\n",
      "Epoch: 36 \tTraining Loss: 1.506960 \tValidation Loss: 1.494771\n",
      "\t\tTraining Acc:  33.054 \t\tValidation Acc:33.537\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 9/10\n",
      "--------------------------------------------------\n",
      "Epoch: 37 \tTraining Loss: 1.511394 \tValidation Loss: 1.474983\n",
      "\t\tTraining Acc:  31.864 \t\tValidation Acc:36.098\n",
      "--------------------------------------------------\n",
      "Early Stopping Hit\n",
      "--------------------------------------------------\n",
      "Training Completed with best model having loss of 1.4380437967253894\n"
     ]
    }
   ],
   "source": [
    "print('\\nTraining of Model:')\n",
    "model_nn = train_model(model_nn, criterion, optimizer_ft, num_epochs = 50, model_checkpoint = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S_7KDWMvXSUr"
   },
   "outputs": [],
   "source": [
    "os.rename('model.pt','model_ann.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QxO_Oez5vf9m"
   },
   "source": [
    "# TASK 6: Tensorboard\n",
    "> Using Tensorboard to display the accuracy and loss graphs of the training. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 838
    },
    "colab_type": "code",
    "id": "d34iE1H4N5Tf",
    "outputId": "c42ba68c-c23b-4ca1-eafe-668df3cecdd2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 1027), started 1:16:06 ago. (Use '!kill 1027' to kill it.)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        (async () => {\n",
       "            const url = await google.colab.kernel.proxyPort(6006, {\"cache\": true});\n",
       "            const iframe = document.createElement('iframe');\n",
       "            iframe.src = url;\n",
       "            iframe.setAttribute('width', '100%');\n",
       "            iframe.setAttribute('height', '800');\n",
       "            iframe.setAttribute('frameborder', 0);\n",
       "            document.body.appendChild(iframe);\n",
       "        })();\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/tensorboard/ann/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "colab_type": "code",
    "id": "MKSJM5AMfHsm",
    "outputId": "31505858-2074-4b41-90f5-4236bfc74e15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[10  1  3  6  7]\n",
      " [10 98 12 17 31]\n",
      " [55 26 84 56 31]\n",
      " [10 22 35 58 27]\n",
      " [45 44 34 27 71]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_verification(dataloaders['test'],batch_size['test'],model_nn,n_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 808
    },
    "colab_type": "code",
    "id": "KOzlpBGMfQdd",
    "outputId": "197ffc61-7232-4bc0-e901-6bfb798d3a8d"
   },
   "outputs": [],
   "source": [
    "visualize_model(model_nn, num_images=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eHFjCqkPPqv2"
   },
   "source": [
    "# TASK 7: Building a Convolutional Neural Network\n",
    "* In this we will be using `Transfer Learning`\n",
    "* We will make use of `DenseNet161` (as feature extractor)\n",
    "* We will train only the `Classification` layers\n",
    "* For Optimizer, we are using `SGD` with learning rate 0.01\n",
    "* For Loss Function, we are using `CrossEntropyLoss` due to multi-class classification \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "knHZx8M-IGr7"
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "current_time = str(datetime.datetime.now().timestamp())\n",
    "train_log_dir = 'logs/tensorboard/cnn/train/' + current_time\n",
    "test_log_dir = 'logs/tensorboard/cnn/test/' + current_time\n",
    "train_summary_writer = summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = summary.create_file_writer(test_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "zCzxacPK2PM9",
    "outputId": "7f3d1aff-f9a6-49da-96d0-57b1c7f6e6e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(816, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(864, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(912, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(912, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(960, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1008, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1008, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer25): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer26): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer27): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer28): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer29): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer30): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer31): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer32): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer33): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer34): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer35): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer36): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(2112, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2112, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(2160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace=True)\n",
       "        (conv1): Conv2d(2160, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(2208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=2208, out_features=1104, bias=True)\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): Linear(in_features=1104, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes = len(dataset_classes)\n",
    "\n",
    "model_ft = models.densenet161(pretrained=True)\n",
    "# Using Model as Feature Extractor\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = model_ft.classifier.in_features\n",
    "# model_ft.classifier = nn.Linear(num_ftrs, n_classes)\n",
    "model_ft.classifier = nn.Sequential(nn.Linear(num_ftrs, int(num_ftrs/2)), nn.Dropout(), nn.Linear(int(num_ftrs/2), n_classes))\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q41ImjwH10Vx"
   },
   "outputs": [],
   "source": [
    "# Cross Entropy Loss \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "decay = 0.0001\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=lr, momentum = momentum, weight_decay = decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ZJ50ms3M1w7M",
    "outputId": "8e12761c-79a4-47a6-a939-5c7ca662e06b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training of Model:\n",
      "Epoch: 1 \tTraining Loss: 1.133392 \tValidation Loss: 0.610399\n",
      "\t\tTraining Acc:  67.114 \t\tValidation Acc:94.756\n",
      "\t\tValidation loss decreased (inf --> 0.610399).\n",
      "Model Saved: model.pt\n",
      "Epoch: 2 \tTraining Loss: 0.610446 \tValidation Loss: 0.327109\n",
      "\t\tTraining Acc:  87.782 \t\tValidation Acc:96.585\n",
      "\t\tValidation loss decreased (0.610399 --> 0.327109).\n",
      "Model Saved: model.pt\n",
      "Epoch: 3 \tTraining Loss: 0.437969 \tValidation Loss: 0.230156\n",
      "\t\tTraining Acc:  89.811 \t\tValidation Acc:96.220\n",
      "\t\tValidation loss decreased (0.327109 --> 0.230156).\n",
      "Model Saved: model.pt\n",
      "Epoch: 4 \tTraining Loss: 0.360660 \tValidation Loss: 0.192137\n",
      "\t\tTraining Acc:  90.985 \t\tValidation Acc:95.976\n",
      "\t\tValidation loss decreased (0.230156 --> 0.192137).\n",
      "Model Saved: model.pt\n",
      "Epoch: 5 \tTraining Loss: 0.331938 \tValidation Loss: 0.165116\n",
      "\t\tTraining Acc:  90.635 \t\tValidation Acc:96.463\n",
      "\t\tValidation loss decreased (0.192137 --> 0.165116).\n",
      "Model Saved: model.pt\n",
      "Epoch: 6 \tTraining Loss: 0.308979 \tValidation Loss: 0.154982\n",
      "\t\tTraining Acc:  90.589 \t\tValidation Acc:96.341\n",
      "\t\tValidation loss decreased (0.165116 --> 0.154982).\n",
      "Model Saved: model.pt\n",
      "Epoch: 7 \tTraining Loss: 0.292790 \tValidation Loss: 0.139281\n",
      "\t\tTraining Acc:  90.833 \t\tValidation Acc:96.463\n",
      "\t\tValidation loss decreased (0.154982 --> 0.139281).\n",
      "Model Saved: model.pt\n",
      "Epoch: 8 \tTraining Loss: 0.277727 \tValidation Loss: 0.135882\n",
      "\t\tTraining Acc:  91.306 \t\tValidation Acc:96.585\n",
      "\t\tValidation loss decreased (0.139281 --> 0.135882).\n",
      "Model Saved: model.pt\n",
      "Epoch: 9 \tTraining Loss: 0.276386 \tValidation Loss: 0.133808\n",
      "\t\tTraining Acc:  90.696 \t\tValidation Acc:96.098\n",
      "\t\tValidation loss decreased (0.135882 --> 0.133808).\n",
      "Model Saved: model.pt\n",
      "Epoch: 10 \tTraining Loss: 0.269531 \tValidation Loss: 0.123369\n",
      "\t\tTraining Acc:  91.046 \t\tValidation Acc:96.585\n",
      "\t\tValidation loss decreased (0.133808 --> 0.123369).\n",
      "Model Saved: model.pt\n",
      "Epoch: 11 \tTraining Loss: 0.258530 \tValidation Loss: 0.121418\n",
      "\t\tTraining Acc:  91.031 \t\tValidation Acc:96.585\n",
      "\t\tValidation loss decreased (0.123369 --> 0.121418).\n",
      "Model Saved: model.pt\n",
      "Epoch: 12 \tTraining Loss: 0.245420 \tValidation Loss: 0.120092\n",
      "\t\tTraining Acc:  91.428 \t\tValidation Acc:96.829\n",
      "\t\tValidation loss decreased (0.121418 --> 0.120092).\n",
      "Model Saved: model.pt\n",
      "Epoch: 13 \tTraining Loss: 0.243368 \tValidation Loss: 0.121625\n",
      "\t\tTraining Acc:  91.641 \t\tValidation Acc:96.220\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 1/10\n",
      "--------------------------------------------------\n",
      "Epoch: 14 \tTraining Loss: 0.243184 \tValidation Loss: 0.116826\n",
      "\t\tTraining Acc:  91.550 \t\tValidation Acc:96.341\n",
      "\t\tValidation loss decreased (0.120092 --> 0.116826).\n",
      "Model Saved: model.pt\n",
      "Epoch: 15 \tTraining Loss: 0.241140 \tValidation Loss: 0.115094\n",
      "\t\tTraining Acc:  91.779 \t\tValidation Acc:96.585\n",
      "\t\tValidation loss decreased (0.116826 --> 0.115094).\n",
      "Model Saved: model.pt\n",
      "Epoch: 16 \tTraining Loss: 0.243460 \tValidation Loss: 0.114780\n",
      "\t\tTraining Acc:  91.123 \t\tValidation Acc:96.220\n",
      "\t\tValidation loss decreased (0.115094 --> 0.114780).\n",
      "Model Saved: model.pt\n",
      "Epoch: 17 \tTraining Loss: 0.234927 \tValidation Loss: 0.113552\n",
      "\t\tTraining Acc:  91.763 \t\tValidation Acc:96.341\n",
      "\t\tValidation loss decreased (0.114780 --> 0.113552).\n",
      "Model Saved: model.pt\n",
      "Epoch: 18 \tTraining Loss: 0.231478 \tValidation Loss: 0.110141\n",
      "\t\tTraining Acc:  91.946 \t\tValidation Acc:97.195\n",
      "\t\tValidation loss decreased (0.113552 --> 0.110141).\n",
      "Model Saved: model.pt\n",
      "Epoch: 19 \tTraining Loss: 0.230843 \tValidation Loss: 0.107836\n",
      "\t\tTraining Acc:  91.824 \t\tValidation Acc:96.463\n",
      "\t\tValidation loss decreased (0.110141 --> 0.107836).\n",
      "Model Saved: model.pt\n",
      "Epoch: 20 \tTraining Loss: 0.232405 \tValidation Loss: 0.111856\n",
      "\t\tTraining Acc:  91.504 \t\tValidation Acc:96.463\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 1/10\n",
      "--------------------------------------------------\n",
      "Epoch: 21 \tTraining Loss: 0.230298 \tValidation Loss: 0.116329\n",
      "\t\tTraining Acc:  91.931 \t\tValidation Acc:95.976\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 2/10\n",
      "--------------------------------------------------\n",
      "Epoch: 22 \tTraining Loss: 0.226781 \tValidation Loss: 0.110299\n",
      "\t\tTraining Acc:  91.946 \t\tValidation Acc:96.341\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 3/10\n",
      "--------------------------------------------------\n",
      "Epoch: 23 \tTraining Loss: 0.221397 \tValidation Loss: 0.112245\n",
      "\t\tTraining Acc:  92.114 \t\tValidation Acc:96.341\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 4/10\n",
      "--------------------------------------------------\n",
      "Epoch: 24 \tTraining Loss: 0.216681 \tValidation Loss: 0.109794\n",
      "\t\tTraining Acc:  92.251 \t\tValidation Acc:96.463\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 5/10\n",
      "--------------------------------------------------\n",
      "Epoch: 25 \tTraining Loss: 0.209049 \tValidation Loss: 0.115280\n",
      "\t\tTraining Acc:  92.419 \t\tValidation Acc:96.341\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 6/10\n",
      "--------------------------------------------------\n",
      "Epoch: 26 \tTraining Loss: 0.216431 \tValidation Loss: 0.106796\n",
      "\t\tTraining Acc:  92.282 \t\tValidation Acc:96.707\n",
      "\t\tValidation loss decreased (0.107836 --> 0.106796).\n",
      "Model Saved: model.pt\n",
      "Epoch: 27 \tTraining Loss: 0.211799 \tValidation Loss: 0.109976\n",
      "\t\tTraining Acc:  92.328 \t\tValidation Acc:96.341\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 1/10\n",
      "--------------------------------------------------\n",
      "Epoch: 28 \tTraining Loss: 0.204017 \tValidation Loss: 0.111015\n",
      "\t\tTraining Acc:  92.938 \t\tValidation Acc:96.341\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 2/10\n",
      "--------------------------------------------------\n",
      "Epoch: 29 \tTraining Loss: 0.218022 \tValidation Loss: 0.113347\n",
      "\t\tTraining Acc:  91.916 \t\tValidation Acc:95.976\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 3/10\n",
      "--------------------------------------------------\n",
      "Epoch: 30 \tTraining Loss: 0.213846 \tValidation Loss: 0.105664\n",
      "\t\tTraining Acc:  92.267 \t\tValidation Acc:96.829\n",
      "\t\tValidation loss decreased (0.106796 --> 0.105664).\n",
      "Model Saved: model.pt\n",
      "Epoch: 31 \tTraining Loss: 0.213300 \tValidation Loss: 0.104034\n",
      "\t\tTraining Acc:  92.267 \t\tValidation Acc:96.951\n",
      "\t\tValidation loss decreased (0.105664 --> 0.104034).\n",
      "Model Saved: model.pt\n",
      "Epoch: 32 \tTraining Loss: 0.212636 \tValidation Loss: 0.104354\n",
      "\t\tTraining Acc:  92.358 \t\tValidation Acc:96.951\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 1/10\n",
      "--------------------------------------------------\n",
      "Epoch: 33 \tTraining Loss: 0.205634 \tValidation Loss: 0.105725\n",
      "\t\tTraining Acc:  92.404 \t\tValidation Acc:96.829\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 2/10\n",
      "--------------------------------------------------\n",
      "Epoch: 34 \tTraining Loss: 0.194810 \tValidation Loss: 0.110338\n",
      "\t\tTraining Acc:  92.999 \t\tValidation Acc:96.341\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 3/10\n",
      "--------------------------------------------------\n",
      "Epoch: 35 \tTraining Loss: 0.207779 \tValidation Loss: 0.112390\n",
      "\t\tTraining Acc:  92.678 \t\tValidation Acc:95.976\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 4/10\n",
      "--------------------------------------------------\n",
      "Epoch: 36 \tTraining Loss: 0.196906 \tValidation Loss: 0.106914\n",
      "\t\tTraining Acc:  92.968 \t\tValidation Acc:96.707\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 5/10\n",
      "--------------------------------------------------\n",
      "Epoch: 37 \tTraining Loss: 0.202319 \tValidation Loss: 0.108688\n",
      "\t\tTraining Acc:  92.892 \t\tValidation Acc:96.463\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 6/10\n",
      "--------------------------------------------------\n",
      "Epoch: 38 \tTraining Loss: 0.197668 \tValidation Loss: 0.111009\n",
      "\t\tTraining Acc:  92.877 \t\tValidation Acc:96.098\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 7/10\n",
      "--------------------------------------------------\n",
      "Epoch: 39 \tTraining Loss: 0.199814 \tValidation Loss: 0.107654\n",
      "\t\tTraining Acc:  92.999 \t\tValidation Acc:96.707\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 8/10\n",
      "--------------------------------------------------\n",
      "Epoch: 40 \tTraining Loss: 0.199474 \tValidation Loss: 0.105894\n",
      "\t\tTraining Acc:  92.846 \t\tValidation Acc:96.707\n",
      "--------------------------------------------------\n",
      "\t\tEarly Stopping Step: 9/10\n",
      "--------------------------------------------------\n",
      "Epoch: 41 \tTraining Loss: 0.201779 \tValidation Loss: 0.105473\n",
      "\t\tTraining Acc:  92.892 \t\tValidation Acc:96.951\n",
      "--------------------------------------------------\n",
      "Early Stopping Hit\n",
      "--------------------------------------------------\n",
      "Training Completed with best model having loss of 0.10403423690941276\n"
     ]
    }
   ],
   "source": [
    "print('\\nTraining of Model:')\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, num_epochs = 50, model_checkpoint = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6TmMZkg1XaaK"
   },
   "outputs": [],
   "source": [
    "os.rename('model.pt','model_cnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 838
    },
    "colab_type": "code",
    "id": "d5cjLwi8HrHb",
    "outputId": "3927f296-beac-48b5-e06f-85f9fd9d7fe2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 2290), started 1:16:11 ago. (Use '!kill 2290' to kill it.)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        (async () => {\n",
       "            const url = await google.colab.kernel.proxyPort(6007, {\"cache\": true});\n",
       "            const iframe = document.createElement('iframe');\n",
       "            iframe.src = url;\n",
       "            iframe.setAttribute('width', '100%');\n",
       "            iframe.setAttribute('height', '800');\n",
       "            iframe.setAttribute('frameborder', 0);\n",
       "            document.body.appendChild(iframe);\n",
       "        })();\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/tensorboard/cnn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "colab_type": "code",
    "id": "jVnl4-6LciGJ",
    "outputId": "b405846e-9197-4712-a968-8c6993bfbb7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[129   1   1   1   0]\n",
      " [  0 190   1   0   3]\n",
      " [  0   0 159   6   1]\n",
      " [  1   0   7 157   1]\n",
      " [  0   0   0   0 162]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_verification(dataloaders['test'],batch_size['test'],model_ft,n_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 808
    },
    "colab_type": "code",
    "id": "5yov8DsldSU9",
    "outputId": "35b770ea-39ef-41d8-8a30-20d8a829c6ee"
   },
   "outputs": [],
   "source": [
    "visualize_model(model_ft, num_images=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-Ej2t-jN34QR",
    "outputId": "c0b908ac-d63a-4d05-caac-c9bb1b3d3a92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28489"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MF9Hrn8K2i18"
   },
   "source": [
    "# Loading Data for Prediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TV_obeYfAkCj"
   },
   "outputs": [],
   "source": [
    "# Creating Custom Dataset to read images in the order as mentioned in CSV file.\n",
    "class Dphi_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, file_path, transform=None):\n",
    "        self.data = pd.read_csv(file_path)\n",
    "        self.BASE_DIR = './data/animal_dataset_intermediate/test/'\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.BASE_DIR+self.data.filename.iloc[index]).convert('RGB')\n",
    "        label = 0\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Kc-dnsb-y5qc",
    "outputId": "9444349a-5810-4173-aa55-9eed9a30de01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size for Test Dataset: 910\n"
     ]
    }
   ],
   "source": [
    "CSV_PATH = './data/animal_dataset_intermediate/Testing_set_animals.csv'\n",
    "\n",
    "test_transform = transforms.Compose([transforms.Resize((225,225)), transforms.ToTensor()])\n",
    "batch_size = 60\n",
    "\n",
    "test_data = Dphi_Dataset(CSV_PATH, transform=test_transform)\n",
    "test_loaders = DataLoader(test_data, batch_size=batch_size, num_workers=2, shuffle=False)\n",
    "\n",
    "print(\"Size for Test Dataset: %d\"%(len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XvK3DO56HcO2"
   },
   "source": [
    "# Visualizing few images from Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "colab_type": "code",
    "id": "VQm3z3JyFP1D",
    "outputId": "f83fff68-9c6b-4017-d7a3-80acdd586514"
   },
   "outputs": [],
   "source": [
    "# Get one batch of training images\n",
    "dataiter = iter(test_loaders)\n",
    "images, labels = dataiter.next()\n",
    "# Convert images to numpy for display\n",
    "images = images.numpy()\n",
    "\n",
    "# Plot the images in the batch\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "\n",
    "# Display 20 images\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    imshow(images[idx])\n",
    "    ax.set_title('Test Img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FYZWf0xt36l0",
    "outputId": "ebe04d8b-cdf4-416d-b9a4-3a6bf2466930"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30020"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dmp8L_b7v7KS"
   },
   "source": [
    "# TASK 9: Predict\n",
    "> We have saved out model weights on disk. We will be using that for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DKiRwX1z8ZQd"
   },
   "outputs": [],
   "source": [
    "model = models.densenet161(pretrained=False)\n",
    "num_ftrs = model.classifier.in_features\n",
    "# model_ft.classifier = nn.Linear(num_ftrs, n_classes)\n",
    "model.classifier = nn.Sequential(nn.Linear(num_ftrs, int(num_ftrs/2)), nn.Dropout(), nn.Linear(int(num_ftrs/2), n_classes))\n",
    "model = model\n",
    "\n",
    "PATH = 'model_cnn.pt'\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "RESULT_FILE_NAME = f\"Prediction_{PATH}.csv\"\n",
    "all_preds = list()\n",
    "model.eval()\n",
    "for data, _ in dataloaders['test']:\n",
    "    data = data\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    _, preds = torch.max(output, 1)\n",
    "    all_preds.extend(preds.tolist())\n",
    "\n",
    "results = all_preds\n",
    "# results = le.inverse_transform(all_preds)\n",
    "np.savetxt(RESULT_FILE_NAME, results, fmt='%s',delimiter=\",\")\n",
    "print(f\"Shape of Results: {results.shape}\\n File created: {RESULT_FILE_NAME}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Recognize Animals - DPhi",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
